# Choisir le backend: transformers (Hugging Face) ou llama_cpp (GGUF)
BACKEND=transformers

# Si BACKEND=transformers (modèle Hugging Face)
MODEL_ID=Qwen/Qwen2.5-0.5B-Instruct

# Si BACKEND=llama_cpp (mettre le chemin vers un fichier .gguf)
GGUF_PATH=./models/qwen2.5-1.5b-instruct.Q4_K_M.gguf

# Paramètres de génération
MAX_NEW_TOKENS=192
TEMPERATURE=0.7
TOP_P=0.95
REPETITION_PENALTY=1.1
